hydra:
  run:
    dir: /
    
data:
    syndrome_data:
        dataset: '/workspaces/deep-learning-experiment/data/raw_data/syndrome_data'
    non_syndrome_data:
        dataset: '/workspaces/deep-learning-experiment/data/raw_data/non_syndrome_data'                         
                         
staging:
    syndrome_data:
        dataset: '/workspaces/deep-learning-experiment/data/processed_data/syndrome_data/syndrome_data.h5'
    non_syndrome_data:
        dataset: '/workspaces/deep-learning-experiment/data/processed_data/non_syndrome_data/non_syndrome_data.h5'
                    
splitting_data:
    shuffle: True
    test_size: 0.2
    training_data:
        dataset: '/workspaces/deep-learning-experiment/data/modelling_data/training_dataset.h5'
    testing_data:
        dataset: '/workspaces/deep-learning-experiment/data/modelling_data/testing_data.h5'
    

modelling:
    architecture: "ResNet50"
    wandb_config:
        entity_name: deep_learning_experiment
        project_name: deep_learning_experiment
        tags: [deep_learning_experiment_alexnet_adam]
        parameters:
            learning_rate: [0.00001, 0.01]
            dropout: [0.0, 0.5]
            batch_size: [128, 256]
            epochs: [10, 20]
    optimizer:
        module: keras.optimizers
        name: Adam
    preprocessing:
        module: sklearn.preprocessing
        name: StandardScaler
    bayesian_optimization:
        init_points: 10
        n_inter: 100
    num_classes: 1
    rotation_range: 15
    num_augmentations: 3
    random_state: 42
    models_dir: /deep-learning-experiment/models/NN/
